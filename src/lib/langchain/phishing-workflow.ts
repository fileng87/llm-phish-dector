import { PhishingDetectionResult } from '@/types/phishing-detection';
import { BaseChatModel } from '@langchain/core/language_models/chat_models';
import {
  AIMessage,
  BaseMessage,
  HumanMessage,
  SystemMessage,
} from '@langchain/core/messages';
import { JsonOutputParser } from '@langchain/core/output_parsers';
import { Runnable } from '@langchain/core/runnables';
import { END, START, StateGraph } from '@langchain/langgraph';
import { ToolNode } from '@langchain/langgraph/prebuilt';

import {
  PHISHING_DETECTION_SYSTEM_PROMPT,
  generateAnalysisPrompt,
} from './prompts';
import { availableTools } from './tools';

/**
 * å®šç¾©å·¥ä½œæµçš„ç‹€æ…‹ã€‚
 * æˆ‘å€‘åªä½¿ç”¨ä¸€å€‹ `messages` é™£åˆ—ï¼Œé€™æ˜¯ä¸€å€‹å¸¸è¦‹ä¸”å¼·å¤§çš„æ¨¡å¼ã€‚
 */
export interface WorkflowState {
  messages: BaseMessage[];
}

const AGENT_NODE = 'agent';
const TOOLS_NODE = 'tools';

/**
 * é‡£é­šéƒµä»¶åˆ†æå·¥ä½œæµ
 *
 * é€™å€‹ç‰ˆæœ¬æ¢å¾©äº†ä½¿ç”¨ LangGraph çš„ ReAct (Reason+Act) Agent å¾ªç’°ã€‚
 * ä¸»è¦ç”±å…©å€‹ç¯€é»çµ„æˆï¼š
 * 1. agent: è² è²¬æ€è€ƒã€å‘¼å« LLM ä¸¦æ±ºå®šæ˜¯å¦ä½¿ç”¨å·¥å…·ã€‚
 * 2. tools: è² è²¬åŸ·è¡Œ `agent` ç¯€é»è«‹æ±‚çš„å·¥å…·ã€‚
 *
 * é€™å€‹å¾ªç’°æœƒæŒçºŒé€²è¡Œ (agent -> tools -> agent)ï¼Œç›´åˆ° `agent` ç¯€é»èªç‚ºè³‡è¨Šå……è¶³ï¼Œ
 * ä¸¦çµ¦å‡ºæœ€çµ‚ç­”æ¡ˆç‚ºæ­¢ã€‚
 */
export class PhishingAnalysisWorkflow {
  private modelWithTools: Runnable;
  private parser: JsonOutputParser;

  constructor(model: BaseChatModel) {
    if (!model || !model.bindTools) {
      throw new Error('å¿…é ˆæä¾›ä¸€å€‹æœ‰æ•ˆçš„ã€æ”¯æ´å·¥å…·ç¶å®šçš„æ¨¡å‹');
    }
    // ç¶å®šå·¥å…·åˆ°æ¨¡å‹ï¼Œè®“æ¨¡å‹çŸ¥é“æœ‰å“ªäº›å·¥å…·å¯ç”¨
    this.modelWithTools = model.bindTools(availableTools);
    this.parser = new JsonOutputParser();
  }

  /**
   * å‰µå»ºä¸¦è¿”å›å·²ç·¨è­¯çš„å·¥ä½œæµåœ–ã€‚
   */
  public getWorkflow() {
    // 1. åˆå§‹åŒ– StateGraphï¼Œä¸¦å®šç¾©ç‹€æ…‹çš„çµæ§‹
    const workflow = new StateGraph<WorkflowState>({
      channels: {
        messages: {
          value: (x, y) => x.concat(y),
          default: () => [],
        },
      },
    });

    // 2. å®šç¾©ç¯€é»
    workflow.addNode(AGENT_NODE, async (state: WorkflowState) => {
      const response = await this.modelWithTools.invoke(state.messages);
      return { messages: [response] };
    });
    workflow.addNode(TOOLS_NODE, new ToolNode(availableTools));

    // 3. å®šç¾©é‚Š (Edges)
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    workflow.addEdge(START, AGENT_NODE as any);

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    workflow.addConditionalEdges(AGENT_NODE as any, (state: WorkflowState) => {
      const lastMessage = state.messages[state.messages.length - 1];
      if (!(lastMessage instanceof AIMessage)) {
        throw new Error('é æœŸæœ€å¾Œä¸€æ¢è¨Šæ¯æ˜¯ AIMessage');
      }

      if (lastMessage.tool_calls && lastMessage.tool_calls.length > 0) {
        return TOOLS_NODE;
      }
      return END;
    });

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    workflow.addEdge(TOOLS_NODE as any, AGENT_NODE as any);

    // 4. ç·¨è­¯å·¥ä½œæµ
    return workflow.compile();
  }

  /**
   * åŸ·è¡Œåˆ†ææµç¨‹
   */
  async analyze(emailContent: string): Promise<PhishingDetectionResult> {
    console.log('ğŸš€ é–‹å§‹åˆ†æå·¥ä½œæµ...');
    const compiledWorkflow = this.getWorkflow();

    const initialState: WorkflowState = {
      messages: [
        new SystemMessage(PHISHING_DETECTION_SYSTEM_PROMPT),
        new HumanMessage(generateAnalysisPrompt(emailContent)),
      ],
    };

    const finalState = await compiledWorkflow.invoke(initialState, {
      recursionLimit: 25,
    });

    const lastMessage = finalState.messages[finalState.messages.length - 1];

    if (
      lastMessage &&
      lastMessage.content &&
      typeof lastMessage.content === 'string'
    ) {
      return this.parseResult(lastMessage.content);
    } else {
      throw new Error('åˆ†ææµç¨‹çµæŸä½†æœªç”¢ç”Ÿæœ‰æ•ˆçµæœ');
    }
  }

  private async parseResult(content: string): Promise<PhishingDetectionResult> {
    try {
      const parsedJson = await this.parser.parse(content);
      return this.validateAndFormatResult(parsedJson);
    } catch {
      const jsonMatch = content.match(/```(json)?\n([\s\S]*?)\n```/);
      if (jsonMatch && jsonMatch[2]) {
        try {
          const parsedJson = JSON.parse(jsonMatch[2]);
          return this.validateAndFormatResult(parsedJson);
        } catch {
          throw new Error('ç„¡æ³•è§£ææ¨¡å‹å›æ‡‰çš„ JSON å…§å®¹');
        }
      } else {
        throw new Error('æ¨¡å‹å›æ‡‰æ ¼å¼ä¸æ­£ç¢ºï¼Œæ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON å€å¡Š');
      }
    }
  }

  private validateAndFormatResult(rawResult: unknown): PhishingDetectionResult {
    if (typeof rawResult !== 'object' || rawResult === null) {
      throw new Error('åˆ†æçµæœæ ¼å¼éŒ¯èª¤ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ç‰©ä»¶');
    }

    const result = rawResult as Record<string, unknown>;

    const isPhishing =
      typeof result.isPhishing === 'boolean' ? result.isPhishing : false;
    const confidenceScore =
      typeof result.confidenceScore === 'number'
        ? Math.max(0, Math.min(100, result.confidenceScore))
        : 50;

    const suspiciousPoints = Array.isArray(result.suspiciousPoints)
      ? result.suspiciousPoints
          .map((p) => (typeof p === 'string' ? p.trim() : JSON.stringify(p)))
          .filter(Boolean)
      : [];

    const explanation =
      typeof result.explanation === 'string'
        ? result.explanation.trim()
        : 'ç„¡è©³ç´°è§£é‡‹';

    const riskLevel =
      typeof result.riskLevel === 'string' &&
      ['low', 'medium', 'high'].includes(result.riskLevel)
        ? (result.riskLevel as 'low' | 'medium' | 'high')
        : 'medium';

    return {
      isPhishing,
      confidenceScore,
      suspiciousPoints,
      explanation,
      riskLevel,
      timestamp: new Date().toISOString(),
    };
  }
}
